{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b20d13cf-24c7-4fea-8392-6739a2e0ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture# Suppose Data X is a 2-D Numpy array (One apple has two features, size and flavor)\n",
    "from data_loader import data_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fe3d24-d877-4172-9340-963223cec465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ellipses(gmm, ax):\n",
    "    colors = [\"navy\", \"turquoise\", \"darkorange\"]\n",
    "\n",
    "    for n in range(gmm.means_.shape[0]):\n",
    "        if gmm.covariance_type == \"full\":\n",
    "            covariances = gmm.covariances_[n][:, :]\n",
    "        elif gmm.covariance_type == \"tied\":\n",
    "            covariances = gmm.covariances_[:, :]\n",
    "        elif gmm.covariance_type == \"diag\":\n",
    "            covariances = np.diag(gmm.covariances_[n][:])\n",
    "        elif gmm.covariance_type == \"spherical\":\n",
    "            covariances = np.eye(gmm.means_.shape[1]) * gmm.covariances_[n]\n",
    "        v, w = np.linalg.eigh(covariances)\n",
    "        u = w[0] / np.linalg.norm(w[0])\n",
    "        angle = np.arctan2(u[1], u[0])\n",
    "        angle = 180 * angle / np.pi  # convert to degrees\n",
    "        v = 2.0 * np.sqrt(2.0) * np.sqrt(v)\n",
    "        ell = mpl.patches.Ellipse(\n",
    "            gmm.means_[n, :2], v[0], v[1], angle=180 + angle\n",
    "        )\n",
    "        ell.set_clip_box(ax.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        ax.add_artist(ell)\n",
    "        #ax.set_aspect(\"equal\", \"datalim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f13a33-eb7f-4fc3-be8a-c86bbe3ab268",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m compute_reduction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      5\u001b[0m n_training_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 7\u001b[0m d_loader \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_reduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_training_samples\u001b[49m\u001b[43m)\u001b[49m               \n\u001b[1;32m      9\u001b[0m X \u001b[38;5;241m=\u001b[39m d_loader\u001b[38;5;241m.\u001b[39mget_z(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[:,\u001b[38;5;241m7\u001b[39m:\u001b[38;5;241m9\u001b[39m]\n\u001b[1;32m     11\u001b[0m GMM \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39mn_clusters, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  init_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X)\n",
      "File \u001b[0;32m~/Projects/MPC_drone/mpc_quad/gp/data_loader.py:25\u001b[0m, in \u001b[0;36mdata_loader.__init__\u001b[0;34m(self, filename, compute_reduction, number_of_training_samples)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, compute_reduction, number_of_training_samples):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary \u001b[38;5;241m=\u001b[39m \u001b[43mload_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# takes every *compute_reduction* index along first axis \u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_reduction \u001b[38;5;241m=\u001b[39m compute_reduction\n",
      "File \u001b[0;32m~/Projects/MPC_drone/mpc_quad/gp/data_loader.py:17\u001b[0m, in \u001b[0;36mload_dict\u001b[0;34m(filename_)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dict\u001b[39m(filename_):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m         ret_di \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret_di\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.pkl'"
     ]
    }
   ],
   "source": [
    "filename = 'trajectory.pkl'\n",
    "\n",
    "n_clusters = 10\n",
    "compute_reduction = 10\n",
    "n_training_samples = 100\n",
    "\n",
    "d_loader = data_loader(filename, compute_reduction, n_training_samples)               \n",
    "\n",
    "X = d_loader.get_z(training=False)[:,7:9]\n",
    "\n",
    "GMM = GaussianMixture(n_components=n_clusters, random_state=0, n_init=3,  init_params='kmeans').fit(X)\n",
    "y = GMM.predict(X)\n",
    "\n",
    "# sort samples into predicted classes for plotting\n",
    "group = [np.array([0, 0]).reshape(1,-1)]*n_clusters\n",
    "print(group[0].shape)\n",
    "for i in range(X.shape[0]):\n",
    "    #print(group[y[i]])\n",
    "    #print(group[y[i]])\n",
    "    #print(X[i])\n",
    "    group[y[i]] = np.append(group[y[i]], X[i].reshape(1,-1), axis=0)\n",
    "\n",
    "for n in range(len(group)):\n",
    "    group[n] = group[n][1:,:]\n",
    "    print(group[n].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2ec44-76be-4be7-9d44-9be0cf1c068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best representatives of each class\n",
    "centers = np.empty(shape=(GMM.n_components, X.shape[1]))\n",
    "for i in range(GMM.n_components):\n",
    "    density = scipy.stats.multivariate_normal(cov=GMM.covariances_[i], mean=GMM.means_[i]).logpdf(X)\n",
    "    centers[i, :] = X[np.argmax(density)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be9d15-ba27-4fd4-b983-0e8200dac7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(10,6), dpi=100)\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n",
    "fig, ax = plt.subplots(figsize=(10,6), dpi=100)\n",
    "\n",
    "\n",
    "for n in range(len(group)):\n",
    "    plt.scatter(group[n][:,0], group[n][:,1])\n",
    "plt.scatter(GMM.means_[:,0], GMM.means_[:,1])\n",
    "plt.scatter(centers[:,0], centers[:,1], marker='+')\n",
    "plt.legend([f'{n}' for n in range(len(group))])\n",
    "make_ellipses(GMM, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf587c3-2073-4849-b42e-bbc3d1d3d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_clusters = 10\n",
    "\n",
    "X = d_loader.get_z(training=False)\n",
    "\n",
    "GMM = GaussianMixture(n_components=n_clusters, random_state=0, n_init=3,  init_params='kmeans').fit(X)\n",
    "y = GMM.predict(X)\n",
    "\n",
    "# sort samples into predicted classes for plotting\n",
    "group = [np.zeros((1, X.shape[1]))]*n_clusters\n",
    "#print(group[0].shape)\n",
    "for i in range(X.shape[0]):\n",
    "    group[y[i]] = np.append(group[y[i]], X[i].reshape(1,-1), axis=0)\n",
    "\n",
    "for n in range(len(group)):\n",
    "    group[n] = group[n][1:,:]\n",
    "    print(group[n].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c339b44-0b37-4b93-8f43-494c59f1fdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14073622-d6c3-4c35-a4ea-f039c838a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis(n_components=2)\n",
    "clf.fit(X, y)\n",
    "\n",
    "X_LDA = clf.transform(X)\n",
    "y_LDA = clf.predict(X)\n",
    "\n",
    "\n",
    "means_LDA = clf.transform(GMM.means_)\n",
    "\n",
    "# sort samples into predicted classes for plotting\n",
    "group = [np.zeros((1, X_LDA.shape[1]))]*n_clusters\n",
    "#print(group[0].shape)\n",
    "for i in range(X_LDA.shape[0]):\n",
    "    group[y_LDA[i]] = np.append(group[y_LDA[i]], X_LDA[i].reshape(1,-1), axis=0)\n",
    "\n",
    "for n in range(len(group)):\n",
    "    group[n] = group[n][1:,:]\n",
    "    print(group[n].shape)\n",
    "    \n",
    "    \n",
    "\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n",
    "fig, ax = plt.subplots(figsize=(10,6), dpi=100)\n",
    "\n",
    "\n",
    "for n in range(len(group)):\n",
    "    plt.scatter(group[n][:,0], group[n][:,1])\n",
    "plt.scatter(means_LDA[:,0], means_LDA[:,1])\n",
    "plt.legend([f'{n}' for n in range(len(group))])\n",
    "#make_ellipses(GMM, ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4c2d4-1db5-4a9f-8107-1b146d33f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6), dpi=100)\n",
    "\n",
    "\n",
    "for n in range(len(group)):\n",
    "    plt.scatter(group[n][:,0], group[n][:,1])\n",
    "plt.scatter(GMM.means_[:,0], GMM.means_[:,1])\n",
    "plt.legend([f'{n}' for n in range(len(group))])\n",
    "make_ellipses(GMM, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
